{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farwa-01/SEG_Training_Results_60_Site_DKA_M18_A_Phase/blob/main/Feature_Selection_by_RFFI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error, r2_score, median_absolute_error, explained_variance_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "# Mount Google Drive to access files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset from Google Drive\n",
        "file_path = '/content/drive/MyDrive/SEG Forecast/60-Site_DKA-M18_A-Phase.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Select only the necessary columns\n",
        "df = df[['Active_Power', 'Global_Horizontal_Radiation', 'Weather_Temperature_Celsius',\n",
        "         'Weather_Relative_Humidity', 'Diffuse_Horizontal_Radiation', 'Wind_Speed',\n",
        "         'Performance_Ratio']]\n",
        "\n",
        "# Convert the relevant columns to numeric (if not already)\n",
        "numeric_columns = ['Active_Power', 'Global_Horizontal_Radiation', 'Weather_Temperature_Celsius',\n",
        "                   'Weather_Relative_Humidity', 'Diffuse_Horizontal_Radiation', 'Wind_Speed',\n",
        "                   'Performance_Ratio']\n",
        "\n",
        "# Use .loc to avoid SettingWithCopyWarning\n",
        "df.loc[:, numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Handle missing values by filling them with the mean of the column\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Define features (X) and target (y) for Linear Regression\n",
        "X = df[['Global_Horizontal_Radiation', 'Weather_Temperature_Celsius',\n",
        "                   'Performance_Ratio',  'Wind_Speed']]\n",
        "y = df['Active_Power']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Polynomial Features Transformation\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# Initialize and train Linear Regression model\n",
        "model = LinearRegression()\n",
        "start_time = time.time()\n",
        "model.fit(X_train_poly, y_train)\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Predict using the trained model\n",
        "y_pred = model.predict(X_test_poly)\n",
        "\n",
        "# Calculate and display model performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "medae = median_absolute_error(y_test, y_pred)\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Polynomial Linear Regression Model (Degree 2)\")\n",
        "print(f\"Training Time: {training_time:.4f} seconds\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "print(f\"Median Absolute Error: {medae}\")\n",
        "print(f\"Explained Variance Score: {evs}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5syZwzd01xh",
        "outputId": "51168b5b-275b-4f4f-8657-bd06d99707d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Polynomial Linear Regression Model (Degree 2)\n",
            "Training Time: 2.8890 seconds\n",
            "Mean Squared Error: 1.0680795457206786\n",
            "R-squared: 0.518536811618879\n",
            "Median Absolute Error: 0.10640565056848461\n",
            "Explained Variance Score: 0.5185384169217706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate cell for Huber Loss\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "\n",
        "# Initialize and train Huber Regressor\n",
        "huber_model = HuberRegressor()\n",
        "start_time = time.time()\n",
        "huber_model.fit(X_train_poly, y_train)\n",
        "end_time = time.time()\n",
        "training_time_huber = end_time - start_time\n",
        "\n",
        "# Predict using the trained Huber model\n",
        "y_pred_huber = huber_model.predict(X_test_poly)\n",
        "\n",
        "# Calculate Huber Loss\n",
        "def huber_loss(y_true, y_pred, delta=1.0):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = np.abs(error) <= delta\n",
        "    squared_loss = np.square(error) / 2\n",
        "    linear_loss = delta * (np.abs(error) - delta / 2)\n",
        "    return np.where(is_small_error, squared_loss, linear_loss).mean()\n",
        "\n",
        "huber_loss_value = huber_loss(y_test, y_pred_huber)\n",
        "\n",
        "print(f\"\\nHuber Regression Model\")\n",
        "print(f\"Training Time: {training_time_huber:.4f} seconds\")\n",
        "print(f\"Huber Loss: {huber_loss_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCWAojfd0z5Q",
        "outputId": "c3d4cf0a-18bb-4d8b-ff0f-79264bacaa67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Huber Regression Model\n",
            "Training Time: 18.6689 seconds\n",
            "Huber Loss: 0.38119301558465246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXiP3Iynr5x9",
        "outputId": "930eb832-fbe4-4e6d-b5a4-cd4621f0da8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Root Mean Squared Error (RMSE): 1.034140913165743\n",
            "Mean Absolute Error (MAE): 0.6128964565104204\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "# Calculate and display Lasso Regression model performance\n",
        "\n",
        "rmse_lasso = np.sqrt(mse_lasso)\n",
        "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_lasso}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_lasso}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error, explained_variance_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "import time\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/SEG Forecast/60-Site_DKA-M18_A-Phase.csv')  # Replace with your actual file path\n",
        "\n",
        "# Impute missing values for both features and the target variable\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Selecting features and target before imputation\n",
        "features = data[['Global_Horizontal_Radiation', 'Performance_Ratio',\n",
        "                 'Weather_Temperature_Celsius', 'Wind_Speed']]\n",
        "target = data['Active_Power']\n",
        "\n",
        "# Applying imputation\n",
        "features_imputed = imputer.fit_transform(features)\n",
        "target_imputed = imputer.fit_transform(target.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_imputed, target_imputed, test_size=0.3, random_state=42)\n",
        "\n",
        "# Feature scaling (Random Forest does not necessarily require feature scaling, but doing so can be beneficial in many scenarios)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Model building\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)  # You can adjust the number of trees and other parameters\n",
        "\n",
        "# Measure training time\n",
        "start_time = time.time()\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "end_time = time.time()\n",
        "training_time_rf = end_time - start_time\n",
        "\n",
        "# Predicting the test results\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "\n",
        "# Model evaluation\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "medae = median_absolute_error(y_test, y_pred)\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "# Modified MAPE calculation with log transformation\n",
        "epsilon = 1e-8  # Small number to prevent division by zero\n",
        "mape = np.mean(np.abs((y_test - y_pred) / (y_test + epsilon))) * 100  # Original MAPE calculation\n",
        "log_mape = np.mean(np.abs((np.log1p(y_test) - np.log1p(y_pred)) / (np.log1p(y_test) + epsilon))) * 100  # Log-transformed MAPE\n",
        "\n",
        "# Calculate Huber Loss using Huber Regressor\n",
        "huber_model = HuberRegressor()\n",
        "start_time = time.time()\n",
        "huber_model.fit(X_train_scaled, y_train)\n",
        "end_time = time.time()\n",
        "training_time_huber = end_time - start_time\n",
        "\n",
        "y_pred_huber = huber_model.predict(X_test_scaled)\n",
        "\n",
        "def huber_loss(y_true, y_pred, delta=1.0):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = np.abs(error) <= delta\n",
        "    squared_loss = np.square(error) / 2\n",
        "    linear_loss = delta * (np.abs(error) - delta / 2)\n",
        "    return np.where(is_small_error, squared_loss, linear_loss).mean()\n",
        "\n",
        "huber_loss_value = huber_loss(y_test, y_pred_huber)\n",
        "\n",
        "# Output Results\n",
        "print(f'Random Forest Regression Model')\n",
        "print(f'Training Time: {training_time_rf:.4f} seconds')\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "print(f'R-Squared: {r2}')\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "print(f'Median Absolute Error: {medae}')\n",
        "print(f'Explained Variance Score: {evs}')\n",
        "print(f'Mean Absolute Percentage Error: {mape:.2f}%')\n",
        "print(f'Log-transformed Mean Absolute Percentage Error: {log_mape:.2f}%')\n",
        "\n",
        "print(f'\\nHuber Regression Model')\n",
        "print(f'Training Time: {training_time_huber:.4f} seconds')\n",
        "print(f'Huber Loss: {huber_loss_value}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpbYmpcwLZCm",
        "outputId": "37e4e241-7a1b-40be-8e4e-3a01add34f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regression Model\n",
            "Training Time: 747.2311 seconds\n",
            "Mean Squared Error: 0.19783910968760826\n",
            "Root Mean Squared Error: 0.4447910854408036\n",
            "R-Squared: 0.9116041648865479\n",
            "Mean Absolute Error: 0.12862998479024815\n",
            "Median Absolute Error: 4.000000044468e-06\n",
            "Explained Variance Score: 0.911605223555628\n",
            "Mean Absolute Percentage Error: 391392281.17%\n",
            "Log-transformed Mean Absolute Percentage Error: 203463402.64%\n",
            "\n",
            "Huber Regression Model\n",
            "Training Time: 4.2442 seconds\n",
            "Huber Loss: 0.3914958339057916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error, explained_variance_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "import time\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/SEG Forecast/60-Site_DKA-M18_A-Phase.csv')  # Replace with your actual file path\n",
        "\n",
        "# Impute missing values for both features and the target variable\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Selecting features and target before imputation\n",
        "features = data[['Global_Horizontal_Radiation', 'Performance_Ratio',\n",
        "        'Weather_Temperature_Celsius', 'Wind_Speed']]\n",
        "target = data['Active_Power']\n",
        "\n",
        "# Applying imputation\n",
        "features_imputed = imputer.fit_transform(features)\n",
        "target_imputed = imputer.fit_transform(target.values.reshape(-1,1)).ravel()\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_imputed, target_imputed, test_size=0.3, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Model building\n",
        "mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)  # Adjust hidden_layer_sizes and other parameters as needed\n",
        "mlp_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Measure training time\n",
        "start_time = time.time()\n",
        "mlp_model.fit(X_train_scaled, y_train)\n",
        "end_time = time.time()\n",
        "training_time_mlp = end_time - start_time\n",
        "\n",
        "# Predicting the test results\n",
        "y_pred = mlp_model.predict(X_test_scaled)\n",
        "\n",
        "# Model evaluation\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "medae = median_absolute_error(y_test, y_pred)\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "epsilon = 1e-8  # Small number to prevent division by zero\n",
        "mape = np.mean(np.abs((y_test - y_pred) / (y_test + epsilon))) * 100  # Modified MAPE calculation\n",
        "\n",
        "# Calculate Huber Loss using Huber Regressor\n",
        "huber_model = HuberRegressor()\n",
        "start_time = time.time()\n",
        "huber_model.fit(X_train_scaled, y_train)\n",
        "end_time = time.time()\n",
        "training_time_huber = end_time - start_time\n",
        "\n",
        "y_pred_huber = huber_model.predict(X_test_scaled)\n",
        "def huber_loss(y_true, y_pred, delta=1.0):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = np.abs(error) <= delta\n",
        "    squared_loss = np.square(error) / 2\n",
        "    linear_loss = delta * (np.abs(error) - delta / 2)\n",
        "    return np.where(is_small_error, squared_loss, linear_loss).mean()\n",
        "huber_loss_value = huber_loss(y_test, y_pred_huber)\n",
        "\n",
        "print(f'MLP Model')\n",
        "print(f'Training Time: {training_time_mlp:.4f} seconds')\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "print(f'R-Squared: {r2}')\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "print(f'Median Absolute Error: {medae}')\n",
        "print(f'Explained Variance Score: {evs}')\n",
        "print(f'Mean Absolute Percentage Error: {mape:.2f}%')\n",
        "\n",
        "print(f'\\nHuber Regression Model')\n",
        "print(f'Training Time: {training_time_huber:.4f} seconds')\n",
        "print(f'Huber Loss: {huber_loss_value}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSAmWOSG8rgX",
        "outputId": "accfe311-89ae-46c9-ba03-4672bfb775a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Model\n",
            "Training Time: 809.7209 seconds\n",
            "Mean Squared Error: 0.30506521155345206\n",
            "Root Mean Squared Error: 0.552327087470325\n",
            "R-Squared: 0.8636948266603609\n",
            "Mean Absolute Error: 0.21898351020344634\n",
            "Median Absolute Error: 0.04822462483429496\n",
            "Explained Variance Score: 0.8636952530296471\n",
            "Mean Absolute Percentage Error: 847896510.58%\n",
            "\n",
            "Huber Regression Model\n",
            "Training Time: 3.6629 seconds\n",
            "Huber Loss: 0.3914958339057916\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YhBV2GqSiMJSMpp4Lu5m8H4dvTxCcIpE",
      "authorship_tag": "ABX9TyN5ASeATMvgfweDteJ/65a4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}