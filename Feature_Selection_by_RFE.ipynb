{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1xiNDPJmB271poJOMVIcggKHpDtkBLzEx",
      "authorship_tag": "ABX9TyPIOMu3ls270jfIWCWIl/ML",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farwa-01/SEG_Training_Results_60_Site_DKA_M18_A_Phase/blob/main/Feature_Selection_by_RFE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression**"
      ],
      "metadata": {
        "id": "TZBtXz16nWnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error, r2_score, median_absolute_error, explained_variance_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "# Mount Google Drive to access files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset from Google Drive\n",
        "file_path = '/content/drive/MyDrive/SEG Forecast/60-Site_DKA-M18_A-Phase.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Select only the necessary columns\n",
        "df = df[['Active_Power', 'Global_Horizontal_Radiation', 'Weather_Temperature_Celsius',\n",
        "         'Weather_Relative_Humidity', 'Diffuse_Horizontal_Radiation', 'Wind_Speed',\n",
        "         'Performance_Ratio']]\n",
        "\n",
        "# Convert the relevant columns to numeric (if not already)\n",
        "numeric_columns = ['Active_Power', 'Global_Horizontal_Radiation', 'Weather_Temperature_Celsius',\n",
        "                   'Weather_Relative_Humidity', 'Diffuse_Horizontal_Radiation', 'Wind_Speed',\n",
        "                   'Performance_Ratio']\n",
        "\n",
        "# Use .loc to avoid SettingWithCopyWarning\n",
        "df.loc[:, numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Handle missing values by filling them with the mean of the column\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Define features (X) and target (y) for Linear Regression\n",
        "X = df[['Global_Horizontal_Radiation', 'Weather_Temperature_Celsius',\n",
        "                   'Weather_Relative_Humidity',  'Wind_Speed']]\n",
        "y = df['Active_Power']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Polynomial Features Transformation\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# Initialize and train Linear Regression model\n",
        "model = LinearRegression()\n",
        "start_time = time.time()\n",
        "model.fit(X_train_poly, y_train)\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Predict using the trained model\n",
        "y_pred = model.predict(X_test_poly)\n",
        "\n",
        "# Calculate and display model performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "medae = median_absolute_error(y_test, y_pred)\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Polynomial Linear Regression Model (Degree 2)\")\n",
        "print(f\"Training Time: {training_time:.4f} seconds\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "print(f\"Median Absolute Error: {medae}\")\n",
        "print(f\"Explained Variance Score: {evs}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HH7QiiPbxbN",
        "outputId": "b32c0495-16a8-4e3d-a464-cde4a9d0337d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-e71858ecbad6>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial Linear Regression Model (Degree 2)\n",
            "Training Time: 0.9884 seconds\n",
            "Mean Squared Error: 1.0984412126968792\n",
            "R-squared: 0.504850541672511\n",
            "Median Absolute Error: 0.10756436868040309\n",
            "Explained Variance Score: 0.504852662410101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate cell for Huber Loss\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "\n",
        "# Initialize and train Huber Regressor\n",
        "huber_model = HuberRegressor()\n",
        "start_time = time.time()\n",
        "huber_model.fit(X_train_poly, y_train)\n",
        "end_time = time.time()\n",
        "training_time_huber = end_time - start_time\n",
        "\n",
        "# Predict using the trained Huber model\n",
        "y_pred_huber = huber_model.predict(X_test_poly)\n",
        "\n",
        "# Calculate Huber Loss\n",
        "def huber_loss(y_true, y_pred, delta=1.0):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = np.abs(error) <= delta\n",
        "    squared_loss = np.square(error) / 2\n",
        "    linear_loss = delta * (np.abs(error) - delta / 2)\n",
        "    return np.where(is_small_error, squared_loss, linear_loss).mean()\n",
        "\n",
        "huber_loss_value = huber_loss(y_test, y_pred_huber)\n",
        "\n",
        "print(f\"\\nHuber Regression Model\")\n",
        "print(f\"Training Time: {training_time_huber:.4f} seconds\")\n",
        "print(f\"Huber Loss: {huber_loss_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKtFM0JIc-Eu",
        "outputId": "af29b014-42e0-4a8b-b9bd-15310abd571d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Huber Regression Model\n",
            "Training Time: 30.5854 seconds\n",
            "Huber Loss: 0.38904652624891756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "# Calculate and display Lasso Regression model performance\n",
        "\n",
        "rmse_lasso = np.sqrt(mse_lasso)\n",
        "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_lasso}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_lasso}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS2VhbQ7r4Vi",
        "outputId": "a4d34022-2d03-48dd-ec63-3ddf9e76f27b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 1.04819903961482\n",
            "Mean Absolute Error (MAE): 0.6209463466643363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest**"
      ],
      "metadata": {
        "id": "1tlQTstAngRl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error, explained_variance_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "import time\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/SEG Forecast/60-Site_DKA-M18_A-Phase.csv')  # Replace with your actual file path\n",
        "\n",
        "# Impute missing values for both features and the target variable\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Selecting features and target before imputation\n",
        "features = data[['Global_Horizontal_Radiation', 'Weather_Relative_Humidity',\n",
        "        'Weather_Temperature_Celsius', 'Wind_Speed']]\n",
        "target = data['Active_Power']\n",
        "\n",
        "# Applying imputation\n",
        "features_imputed = imputer.fit_transform(features)\n",
        "target_imputed = imputer.fit_transform(target.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_imputed, target_imputed, test_size=0.3, random_state=42)\n",
        "\n",
        "# Feature scaling (Random Forest does not necessarily require feature scaling, but doing so can be beneficial in many scenarios)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Model building\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)  # You can adjust the number of trees and other parameters\n",
        "\n",
        "# Measure training time\n",
        "start_time = time.time()\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "end_time = time.time()\n",
        "training_time_rf = end_time - start_time\n",
        "\n",
        "# Predicting the test results\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "\n",
        "# Model evaluation\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "medae = median_absolute_error(y_test, y_pred)\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "epsilon = 1e-8  # Small number to prevent division by zero\n",
        "mape = np.mean(np.abs((y_test - y_pred) / (y_test + epsilon))) * 100  # Modified MAPE calculation\n",
        "\n",
        "# Calculate Huber Loss using Huber Regressor\n",
        "huber_model = HuberRegressor()\n",
        "start_time = time.time()\n",
        "huber_model.fit(X_train_scaled, y_train)\n",
        "end_time = time.time()\n",
        "training_time_huber = end_time - start_time\n",
        "\n",
        "y_pred_huber = huber_model.predict(X_test_scaled)\n",
        "def huber_loss(y_true, y_pred, delta=1.0):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = np.abs(error) <= delta\n",
        "    squared_loss = np.square(error) / 2\n",
        "    linear_loss = delta * (np.abs(error) - delta / 2)\n",
        "    return np.where(is_small_error, squared_loss, linear_loss).mean()\n",
        "huber_loss_value = huber_loss(y_test, y_pred_huber)\n",
        "\n",
        "print(f'Random Forest Regression Model')\n",
        "print(f'Training Time: {training_time_rf:.4f} seconds')\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "print(f'R-Squared: {r2}')\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "print(f'Median Absolute Error: {medae}')\n",
        "print(f'Explained Variance Score: {evs}')\n",
        "print(f'Mean Absolute Percentage Error: {mape:.2f}%')\n",
        "\n",
        "print(f'\\nHuber Regression Model')\n",
        "print(f'Training Time: {training_time_huber:.4f} seconds')\n",
        "print(f'Huber Loss: {huber_loss_value}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3F3KoF6dzP1",
        "outputId": "6e45c1c1-9fad-4522-d892-b188b25c4d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regression Model\n",
            "Training Time: 918.5411 seconds\n",
            "Mean Squared Error: 0.7089243044047953\n",
            "Root Mean Squared Error: 0.8419764274638544\n",
            "R-Squared: 0.6832478875433896\n",
            "Mean Absolute Error: 0.4038921952682804\n",
            "Median Absolute Error: 0.000220666654931837\n",
            "Explained Variance Score: 0.6832498311711465\n",
            "Mean Absolute Percentage Error: 533104652.18%\n",
            "\n",
            "Huber Regression Model\n",
            "Training Time: 6.9867 seconds\n",
            "Huber Loss: 0.39231556156515984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MLP**"
      ],
      "metadata": {
        "id": "23zH5zUNnr_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error, explained_variance_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "import time\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/SEG Forecast/60-Site_DKA-M18_A-Phase.csv')  # Replace with your actual file path\n",
        "\n",
        "# Impute missing values for both features and the target variable\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Selecting features and target before imputation\n",
        "features = data[['Global_Horizontal_Radiation', 'Weather_Relative_Humidity',\n",
        "                 'Weather_Temperature_Celsius', 'Wind_Speed']]\n",
        "target = data['Active_Power']\n",
        "\n",
        "# Applying imputation\n",
        "features_imputed = imputer.fit_transform(features)\n",
        "target_imputed = imputer.fit_transform(target.values.reshape(-1,1)).ravel()\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_imputed, target_imputed, test_size=0.3, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Model building\n",
        "mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)  # Adjust hidden_layer_sizes and other parameters as needed\n",
        "mlp_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Measure training time\n",
        "start_time = time.time()\n",
        "mlp_model.fit(X_train_scaled, y_train)\n",
        "end_time = time.time()\n",
        "training_time_mlp = end_time - start_time\n",
        "\n",
        "# Predicting the test results\n",
        "y_pred = mlp_model.predict(X_test_scaled)\n",
        "\n",
        "# Model evaluation\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "medae = median_absolute_error(y_test, y_pred)\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "epsilon = 1e-8  # Small number to prevent division by zero\n",
        "mape = np.mean(np.abs((y_test - y_pred) / (y_test + epsilon))) * 100  # Modified MAPE calculation\n",
        "\n",
        "# Calculate Huber Loss using Huber Regressor\n",
        "huber_model = HuberRegressor()\n",
        "start_time = time.time()\n",
        "huber_model.fit(X_train_scaled, y_train)\n",
        "end_time = time.time()\n",
        "training_time_huber = end_time - start_time\n",
        "\n",
        "y_pred_huber = huber_model.predict(X_test_scaled)\n",
        "def huber_loss(y_true, y_pred, delta=1.0):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = np.abs(error) <= delta\n",
        "    squared_loss = np.square(error) / 2\n",
        "    linear_loss = delta * (np.abs(error) - delta / 2)\n",
        "    return np.where(is_small_error, squared_loss, linear_loss).mean()\n",
        "huber_loss_value = huber_loss(y_test, y_pred_huber)\n",
        "\n",
        "print(f'MLP Model')\n",
        "print(f'Training Time: {training_time_mlp:.4f} seconds')\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "print(f'R-Squared: {r2}')\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "print(f'Median Absolute Error: {medae}')\n",
        "print(f'Explained Variance Score: {evs}')\n",
        "print(f'Mean Absolute Percentage Error: {mape:.2f}%')\n",
        "\n",
        "print(f'\\nHuber Regression Model')\n",
        "print(f'Training Time: {training_time_huber:.4f} seconds')\n",
        "print(f'Huber Loss: {huber_loss_value}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPqG_8qJshRC",
        "outputId": "8281aa99-dbfc-4748-a155-827246dfa8c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Model\n",
            "Training Time: 398.4803 seconds\n",
            "Mean Squared Error: 0.8805599090135041\n",
            "Root Mean Squared Error: 0.9383815370165294\n",
            "R-Squared: 0.6065599534511581\n",
            "Mean Absolute Error: 0.5130662470765822\n",
            "Median Absolute Error: 0.06813604249471095\n",
            "Explained Variance Score: 0.6066545571042821\n",
            "Mean Absolute Percentage Error: 1023008001.32%\n",
            "\n",
            "Huber Regression Model\n",
            "Training Time: 4.0028 seconds\n",
            "Huber Loss: 0.39231556156515984\n"
          ]
        }
      ]
    }
  ]
}