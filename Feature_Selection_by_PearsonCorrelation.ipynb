{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cE4wL5NtpYOKCDtHeSPmY2kBqJfak6Va",
      "authorship_tag": "ABX9TyMXvz6io05f/f3HIMwdhWok",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farwa-01/SEG_Training_Results_60_Site_DKA_M18_A_Phase/blob/main/Feature_Selection_by_PearsonCorrelation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-doPChAoKei2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0871e62e-4022-4673-fba5-fbdb77890981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Correlation of all 6 parameters with Active Power:\n",
            "Active_Power                    1.000000\n",
            "Global_Horizontal_Radiation     0.699972\n",
            "Weather_Temperature_Celsius     0.331952\n",
            "Weather_Relative_Humidity      -0.322321\n",
            "Diffuse_Horizontal_Radiation    0.391167\n",
            "Wind_Speed                      0.148322\n",
            "Performance_Ratio               0.102860\n",
            "Name: Active_Power, dtype: float64\n",
            "\n",
            "Top 4 features correlated with Active Power:\n",
            "Index(['Global_Horizontal_Radiation', 'Diffuse_Horizontal_Radiation',\n",
            "       'Weather_Temperature_Celsius', 'Wind_Speed'],\n",
            "      dtype='object')\n",
            "\n",
            "Correlation values:\n",
            "Global_Horizontal_Radiation     0.699972\n",
            "Diffuse_Horizontal_Radiation    0.391167\n",
            "Weather_Temperature_Celsius     0.331952\n",
            "Wind_Speed                      0.148322\n",
            "Name: Active_Power, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Mount Google Drive to access files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset from Google Drive\n",
        "# Replace 'your-folder-path' with the actual folder path in your Google Drive\n",
        "file_path = '/content/drive/MyDrive/SEG Forecast/60-Site_DKA-M18_A-Phase.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Select only the necessary columns\n",
        "df = df[['Active_Power', 'Global_Horizontal_Radiation', 'Weather_Temperature_Celsius',\n",
        "         'Weather_Relative_Humidity', 'Diffuse_Horizontal_Radiation', 'Wind_Speed',\n",
        "         'Performance_Ratio']]\n",
        "\n",
        "# Convert the relevant columns to numeric (if not already)\n",
        "numeric_columns = ['Active_Power', 'Global_Horizontal_Radiation', 'Weather_Temperature_Celsius',\n",
        "                   'Weather_Relative_Humidity', 'Diffuse_Horizontal_Radiation', 'Wind_Speed',\n",
        "                   'Performance_Ratio']\n",
        "\n",
        "df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Handle missing values by filling them with the mean of the column\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Calculate correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Extract correlations with Active Power\n",
        "active_power_correlation = correlation_matrix['Active_Power']\n",
        "\n",
        "print(\"Correlation of all 6 parameters with Active Power:\")\n",
        "print(active_power_correlation)\n",
        "\n",
        "# Select the 4 highest correlated features (excluding the target variable itself)\n",
        "top_4_features = active_power_correlation.drop(labels=['Active_Power']).sort_values(ascending=False).index[:4]\n",
        "\n",
        "print(\"\\nTop 4 features correlated with Active Power:\")\n",
        "print(top_4_features)\n",
        "print(\"\\nCorrelation values:\")\n",
        "print(active_power_correlation[top_4_features])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for Linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Select the top 4 features based on correlation values\n",
        "top_4_features = ['Global_Horizontal_Radiation', 'Diffuse_Horizontal_Radiation',\n",
        "                  'Weather_Temperature_Celsius', 'Wind_Speed']\n",
        "\n",
        "# Define features (X) and target (y) for Linear Regression\n",
        "X = df[top_4_features]\n",
        "y = df['Active_Power']\n",
        "\n",
        "# Initialize Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict the target variable\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# Calculate and display model performance\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "r2 = r2_score(y, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "\n",
        "# Display the coefficients for each feature\n",
        "coefficients = pd.DataFrame({'Feature': X.columns, 'Coefficient': model.coef_})\n",
        "print(\"\\nCoefficients for each feature:\")\n",
        "print(coefficients)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRWqTAISoJ4n",
        "outputId": "9a3ae365-9a2a-49c9-922f-1af15cb3f047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 1.1303762567286986\n",
            "R-squared: 0.49103060597946824\n",
            "\n",
            "Coefficients for each feature:\n",
            "                        Feature  Coefficient\n",
            "0   Global_Horizontal_Radiation     0.002933\n",
            "1  Diffuse_Horizontal_Radiation    -0.000286\n",
            "2   Weather_Temperature_Celsius    -0.001837\n",
            "3                    Wind_Speed     0.022169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_squared_error, r2_score, median_absolute_error, explained_variance_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "# Mount Google Drive to access files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset from Google Drive\n",
        "file_path = '/content/drive/MyDrive/SEG Forecast/60-Site_DKA-M18_A-Phase.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Select only the necessary columns\n",
        "df = df[['Active_Power', 'Global_Horizontal_Radiation', 'Weather_Temperature_Celsius',\n",
        "         'Weather_Relative_Humidity', 'Diffuse_Horizontal_Radiation', 'Wind_Speed',\n",
        "         'Performance_Ratio']]\n",
        "\n",
        "# Convert the relevant columns to numeric (if not already)\n",
        "numeric_columns = ['Active_Power', 'Global_Horizontal_Radiation', 'Weather_Temperature_Celsius',\n",
        "                   'Weather_Relative_Humidity', 'Diffuse_Horizontal_Radiation', 'Wind_Speed',\n",
        "                   'Performance_Ratio']\n",
        "\n",
        "# Use .loc to avoid SettingWithCopyWarning\n",
        "df.loc[:, numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Handle missing values by filling them with the mean of the column\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Define features (X) and target (y) for Linear Regression\n",
        "X = df[['Global_Horizontal_Radiation', 'Weather_Temperature_Celsius',\n",
        "        'Diffuse_Horizontal_Radiation', 'Wind_Speed']]\n",
        "y = df['Active_Power']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Polynomial Features Transformation\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train)\n",
        "X_test_poly = poly.transform(X_test)\n",
        "\n",
        "# Initialize and train Linear Regression model\n",
        "model = LinearRegression()\n",
        "start_time = time.time()\n",
        "model.fit(X_train_poly, y_train)\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "\n",
        "# Predict using the trained model\n",
        "y_pred = model.predict(X_test_poly)\n",
        "\n",
        "# Calculate and display model performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "medae = median_absolute_error(y_test, y_pred)\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Polynomial Linear Regression Model (Degree 2)\")\n",
        "print(f\"Training Time: {training_time:.4f} seconds\")\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f\"R-squared: {r2}\")\n",
        "print(f\"Median Absolute Error: {medae}\")\n",
        "print(f\"Explained Variance Score: {evs}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRNrS_JnpbQZ",
        "outputId": "c35f29ab-99b3-4e69-ef20-90e9bded1b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-3eebc2ac55e3>:29: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.loc[:, numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial Linear Regression Model (Degree 2)\n",
            "Training Time: 1.2954 seconds\n",
            "Mean Squared Error: 1.095368277443133\n",
            "R-squared: 0.5062357430003382\n",
            "Median Absolute Error: 0.10837337939377312\n",
            "Explained Variance Score: 0.5062375492571315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate cell for Huber Loss\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "\n",
        "# Initialize and train Huber Regressor\n",
        "huber_model = HuberRegressor()\n",
        "start_time = time.time()\n",
        "huber_model.fit(X_train_poly, y_train)\n",
        "end_time = time.time()\n",
        "training_time_huber = end_time - start_time\n",
        "\n",
        "# Predict using the trained Huber model\n",
        "y_pred_huber = huber_model.predict(X_test_poly)\n",
        "\n",
        "# Calculate Huber Loss\n",
        "def huber_loss(y_true, y_pred, delta=1.0):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = np.abs(error) <= delta\n",
        "    squared_loss = np.square(error) / 2\n",
        "    linear_loss = delta * (np.abs(error) - delta / 2)\n",
        "    return np.where(is_small_error, squared_loss, linear_loss).mean()\n",
        "\n",
        "huber_loss_value = huber_loss(y_test, y_pred_huber)\n",
        "\n",
        "print(f\"\\nHuber Regression Model\")\n",
        "print(f\"Training Time: {training_time_huber:.4f} seconds\")\n",
        "print(f\"Huber Loss: {huber_loss_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_68WqYKBwhE",
        "outputId": "306ac95f-ce5d-4ab2-8b0b-a09844bd14a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Huber Regression Model\n",
            "Training Time: 31.3022 seconds\n",
            "Huber Loss: 0.38638441624625586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E1GWjQlrAG0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "# Calculate and display Lasso Regression model performance\n",
        "\n",
        "rmse_lasso = np.sqrt(mse_lasso)\n",
        "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_lasso}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae_lasso}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSNW3Tl4r16O",
        "outputId": "faa71208-66cd-465b-b1fa-53b5c022cbe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 1.0473362333850713\n",
            "Mean Absolute Error (MAE): 0.6217259788830042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error, explained_variance_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "import time\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/SEG Forecast/60-Site_DKA-M18_A-Phase.csv')  # Replace with your actual file path\n",
        "\n",
        "# Impute missing values for both features and the target variable\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Selecting features and target before imputation\n",
        "features = data[['Global_Horizontal_Radiation', 'Diffuse_Horizontal_Radiation',\n",
        "                 'Weather_Temperature_Celsius', 'Wind_Speed']]\n",
        "target = data['Active_Power']\n",
        "\n",
        "# Applying imputation\n",
        "features_imputed = imputer.fit_transform(features)\n",
        "target_imputed = imputer.fit_transform(target.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_imputed, target_imputed, test_size=0.3, random_state=42)\n",
        "\n",
        "# Feature scaling (Random Forest does not necessarily require feature scaling, but doing so can be beneficial in many scenarios)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Model building\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)  # You can adjust the number of trees and other parameters\n",
        "\n",
        "# Measure training time\n",
        "start_time = time.time()\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "end_time = time.time()\n",
        "training_time_rf = end_time - start_time\n",
        "\n",
        "# Predicting the test results\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "\n",
        "# Model evaluation\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "medae = median_absolute_error(y_test, y_pred)\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "epsilon = 1e-8  # Small number to prevent division by zero\n",
        "mape = np.mean(np.abs((y_test - y_pred) / (y_test + epsilon))) * 100  # Modified MAPE calculation\n",
        "\n",
        "# Calculate Huber Loss using Huber Regressor\n",
        "huber_model = HuberRegressor()\n",
        "start_time = time.time()\n",
        "huber_model.fit(X_train_scaled, y_train)\n",
        "end_time = time.time()\n",
        "training_time_huber = end_time - start_time\n",
        "\n",
        "y_pred_huber = huber_model.predict(X_test_scaled)\n",
        "def huber_loss(y_true, y_pred, delta=1.0):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = np.abs(error) <= delta\n",
        "    squared_loss = np.square(error) / 2\n",
        "    linear_loss = delta * (np.abs(error) - delta / 2)\n",
        "    return np.where(is_small_error, squared_loss, linear_loss).mean()\n",
        "huber_loss_value = huber_loss(y_test, y_pred_huber)\n",
        "\n",
        "print(f'Random Forest Regression Model')\n",
        "print(f'Training Time: {training_time_rf:.4f} seconds')\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "print(f'R-Squared: {r2}')\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "print(f'Median Absolute Error: {medae}')\n",
        "print(f'Explained Variance Score: {evs}')\n",
        "print(f'Mean Absolute Percentage Error: {mape:.2f}%')\n",
        "\n",
        "print(f'\\nHuber Regression Model')\n",
        "print(f'Training Time: {training_time_huber:.4f} seconds')\n",
        "print(f'Huber Loss: {huber_loss_value}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWZrxl551W1Y",
        "outputId": "40a9be12-b96f-47a9-ecf1-f6cb518a5d4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regression Model\n",
            "Training Time: 970.3098 seconds\n",
            "Mean Squared Error: 0.7613700820068826\n",
            "Root Mean Squared Error: 0.872565230803338\n",
            "R-Squared: 0.6598147639480034\n",
            "Mean Absolute Error: 0.42008602263244943\n",
            "Median Absolute Error: 0.0002026666388701401\n",
            "Explained Variance Score: 0.6598167516305387\n",
            "Mean Absolute Percentage Error: 561285194.30%\n",
            "\n",
            "Huber Regression Model\n",
            "Training Time: 6.0132 seconds\n",
            "Huber Loss: 0.3914907238502249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error, explained_variance_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "import time\n",
        "\n",
        "# Load your dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/SEG Forecast/60-Site_DKA-M18_A-Phase.csv')  # Replace with your actual file path\n",
        "\n",
        "# Impute missing values for both features and the target variable\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Selecting features and target before imputation\n",
        "features = data[['Global_Horizontal_Radiation', 'Weather_Temperature_Celsius',\n",
        "        'Diffuse_Horizontal_Radiation', 'Wind_Speed']]\n",
        "target = data['Active_Power']\n",
        "\n",
        "# Applying imputation\n",
        "features_imputed = imputer.fit_transform(features)\n",
        "target_imputed = imputer.fit_transform(target.values.reshape(-1,1)).ravel()\n",
        "\n",
        "# Splitting the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_imputed, target_imputed, test_size=0.3, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Model building\n",
        "mlp_model = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)  # Adjust hidden_layer_sizes and other parameters as needed\n",
        "mlp_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Measure training time\n",
        "start_time = time.time()\n",
        "mlp_model.fit(X_train_scaled, y_train)\n",
        "end_time = time.time()\n",
        "training_time_mlp = end_time - start_time\n",
        "\n",
        "# Predicting the test results\n",
        "y_pred = mlp_model.predict(X_test_scaled)\n",
        "\n",
        "# Model evaluation\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "medae = median_absolute_error(y_test, y_pred)\n",
        "evs = explained_variance_score(y_test, y_pred)\n",
        "epsilon = 1e-8  # Small number to prevent division by zero\n",
        "mape = np.mean(np.abs((y_test - y_pred) / (y_test + epsilon))) * 100  # Modified MAPE calculation\n",
        "\n",
        "# Calculate Huber Loss using Huber Regressor\n",
        "huber_model = HuberRegressor()\n",
        "start_time = time.time()\n",
        "huber_model.fit(X_train_scaled, y_train)\n",
        "end_time = time.time()\n",
        "training_time_huber = end_time - start_time\n",
        "\n",
        "y_pred_huber = huber_model.predict(X_test_scaled)\n",
        "def huber_loss(y_true, y_pred, delta=1.0):\n",
        "    error = y_true - y_pred\n",
        "    is_small_error = np.abs(error) <= delta\n",
        "    squared_loss = np.square(error) / 2\n",
        "    linear_loss = delta * (np.abs(error) - delta / 2)\n",
        "    return np.where(is_small_error, squared_loss, linear_loss).mean()\n",
        "huber_loss_value = huber_loss(y_test, y_pred_huber)\n",
        "\n",
        "print(f'MLP Model')\n",
        "print(f'Training Time: {training_time_mlp:.4f} seconds')\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "print(f'R-Squared: {r2}')\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "print(f'Median Absolute Error: {medae}')\n",
        "print(f'Explained Variance Score: {evs}')\n",
        "print(f'Mean Absolute Percentage Error: {mape:.2f}%')\n",
        "\n",
        "print(f'\\nHuber Regression Model')\n",
        "print(f'Training Time: {training_time_huber:.4f} seconds')\n",
        "print(f'Huber Loss: {huber_loss_value}')"
      ],
      "metadata": {
        "id": "aBlJe01efI6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d348a2-edee-478f-ce08-8304bf03035f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP Model\n",
            "Training Time: 473.2142 seconds\n",
            "Mean Squared Error: 0.8512744541539795\n",
            "Root Mean Squared Error: 0.9226453566533457\n",
            "R-Squared: 0.6196448902115015\n",
            "Mean Absolute Error: 0.5061154432096417\n",
            "Median Absolute Error: 0.06877807782470624\n",
            "Explained Variance Score: 0.6196459972494797\n",
            "Mean Absolute Percentage Error: 980842400.10%\n",
            "\n",
            "Huber Regression Model\n",
            "Training Time: 5.9594 seconds\n",
            "Huber Loss: 0.3914907238502249\n"
          ]
        }
      ]
    }
  ]
}